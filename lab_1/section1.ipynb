{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82de3597-261b-44ab-9e2a-5ead4c38cb31",
   "metadata": {},
   "source": [
    "# Lab #1 Images, optics, and the statistics of light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a01545-d63b-4ec7-ac84-f96b95681649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.visualization import simple_norm\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "from photutils.centroids import centroid_com\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b759b9-0723-438d-b5fa-d6b22979ec46",
   "metadata": {},
   "source": [
    "# Optical Imager\n",
    "**KEY STEPS:**\n",
    "- **Build an optical system that can image the full extent of a Jupiter-sim, resolve Jupiter-sim’s red spot, and separate stars in a globular cluster-sim.**\n",
    "- **Record your imager’s optical design, field-of-view, spatial resolution, and plate scale.**\n",
    "- **How does your imager’s spatial resolution compare to the diffraction limit of your optical system?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c516e9-07ba-4c06-bb23-70eece4d0f2c",
   "metadata": {},
   "source": [
    "*GOAL*: Map an object to an image plane (image formation). \\\n",
    "\\\n",
    "**Thin-lens equation**:\n",
    "\n",
    "$$\n",
    "\\frac{1}{f} = \\frac{1}{i} + \\frac{1}{o},\n",
    "$$\n",
    "where $f = \\text{focal length of thin lens}$, $o = \\text{distance from object to thin lens}$ and $i = \\text{distance from image to thin lens}$. \n",
    "\n",
    "**Focal length** = determines how strongly a system converges or diverges recieved light, determines the extent of an image and the distance between two imaged objects on the focal plane. \\\n",
    "**Focal plane** = where your image comes to a focus \\\n",
    "**Combination of two lenses equation:** \n",
    "$$\n",
    "\\frac{1}{F} = \\frac{1}{f_1} + \\frac{1}{f_2} - \\frac{d}{f_1 * f_2}\n",
    "$$\n",
    "\n",
    "where $F = \\text{combined focal length}$, $f_1 = \\text{focal length of lens 1}$, $f_2 = \\text{focal length of lens 2}$ and $d = \\text{distance between lenses}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a21f6-c980-4045-b118-de8f420aa50b",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63fa13-7494-4c71-9e3d-d4e360b5b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detector\n",
    "#detector_width_pixels = \n",
    "#detector_height_pixels = \n",
    "#pixel_size_um = \n",
    "#wavelength_of_detector_nm ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be812bd-9cb3-499c-98e8-cab48ba054c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lenses\n",
    "#focal_lengths_mm = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54651b7-da79-4e15-9cf5-e34094ead3f0",
   "metadata": {},
   "source": [
    "## 1.1 Plate Scale\n",
    "*GOAL*: Determine an optimal imaging system with a plate scale that would allow to resolve two successive lines of the provided Ronchi mask. \\\n",
    "\\\n",
    "**Plate scale** = angular size of an object that can be imaged onto a particular linear size on the focal plane (angle / unit length) (radians / mm) (*prefered*: arcseconds / pixel)\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{Plate Scale } (p) & = \\frac{\\text{angular separation}\\,(\\text{radians})}{\\text{linear separation} (\\text{mm})} = \\frac{\\text{pixel size (mm)}}{\\text{focal length (mm)}} = \\frac{\\text{radians}}{\\text{pixel}} * \\left(\\frac{206265\\,\\text{arcseconds}}{1\\,\\text{radian}} \\right) = \\frac{\\text{arcseconds}}{\\text{pixel}}\n",
    "\\end{split}\n",
    "$$\n",
    "Note 1: Larger plate scale = larger field of view, smaller plate scale = larger angular resolution\n",
    "Note 2: Larger focal length = smaller plate scale, smaller focal length = larger plate scale\n",
    "Note 3: Larger focal length = smaller field of view, smaller focal length = larger field of view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a8eeb6-e390-4ef1-8994-017176995bd2",
   "metadata": {},
   "source": [
    "### Pre-known Parameters\n",
    "By testing our optical setup, we can determine the distance between Ronchi lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0553b-39ba-4edf-b6a5-983313d6a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number_of_ronchi_lines = \n",
    "#distance_from_detector_to_ronchi_lines_cm ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3aa72b-3758-4eda-b0ed-7c854b89d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ronchi_line_separation_mm_and_arcseconds(number_of_ronchi_lines,\n",
    "                                                       detector_width_pixels,\n",
    "                                                       pixel_size_um,\n",
    "                                                       distance_from_detector_to_ronchi_lines_cm):\n",
    "    # mm\n",
    "    pixel_size_mm = pixel_size_um / 1000 # Convert micro to milli         \n",
    "    detector_width_mm = detector_width_pixels * pixel_size_mm \n",
    "    line_separation_mm = detector_width_mm / (number_of_ronchi_lines - 1)\n",
    "\n",
    "    # arcseconds\n",
    "    distance_from_detector_to_ronchi_lines_mm = distance_from_detector_to_ronchi_lines_cm * 10 # mm\n",
    "    theta_radians = math.atan(line_separation_mm / distance_from_detector_to_ronchi_lines_mm) #radians\n",
    "    theta_degrees = math.degrees(theta_radians) # degrees \n",
    "    theta_arcseconds = theta_degrees * 3600 # arcseconds\n",
    "                                                           \n",
    "    return line_separation_mm, theta_arcseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8833709-5ba1-4c14-b463-3d84cccbae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ronchi_line_separation_mm, ronchi_line_separation_arcseconds = calculate_ronchi_line_separation_mm_and_arcseconds(number_of_ronchi_lines=number_of_ronchi_lines,\n",
    "                                                                                                                  detector_width_pixels=detector_width_pixels,\n",
    "                                                                                                                  pixel_size_um=pixel_size_um,\n",
    "                                                                                                                  distance_from_detector_to_ronchi_lines_cm=distance_from_detector_to_ronchi_lines_cm)\n",
    "\n",
    "print(f\"Separation between Ronchi lines is {np.round(ronchi_line_separation_mm,4)} (mm).\")\n",
    "print(f\"Separation between Ronchi lines is {np.round(ronchi_line_separation_arcseconds,4)} (arcseconds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845091f2-9e56-4775-b0e7-aa7579fc215b",
   "metadata": {},
   "source": [
    "### Determining Plate-Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eefe51-6c49-476a-92ca-bf2fea609cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pixels_to_resolve = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed897a3-82fe-4fb1-848d-47a9fa89e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_needed_plate_scale_and_field_of_view(size_of_object_arcseconds,\n",
    "                                                   detector_width_pixels,\n",
    "                                                   number_of_pixels_to_resolve):\n",
    "    # Plate-scale\n",
    "    plate_scale = size_of_object_arcseconds / number_of_pixels_to_resolve\n",
    "                                                       \n",
    "    # Field of View\n",
    "    field_of_view = plate_scale * detector_width_pixels\n",
    "                                                       \n",
    "    return plate_scale, field_of_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4d0c9-f3b8-4279-8322-0522a3da60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ronchi_lines_plate_scale, ronchi_lines_field_of_view = calculate_needed_plate_scale_and_field_of_view(size_of_object_arcseconds=ronchi_line_separation_arcseconds,\n",
    "                                                                                                      detector_width_pixels=detector_width_pixels,\n",
    "                                                                                                      number_of_pixels_to_resolve=number_of_pixels_to_resolve)\n",
    "\n",
    "                                                                                                      \n",
    "print(f\"Required plate scale for Ronchi line separation is {np.round(ronchi_lines_plate_scale,4)} (arcseconds / pixel).\")\n",
    "print(f\"Field of view corresponding to required plate scale is {np.round(ronchi_lines_field_of_view,4)} (arcseconds).\")\n",
    "                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960764e-3e52-468c-84a2-ca268800b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_given_plate_scale_and_field_of_view(focal_length_mm,\n",
    "                                                  pixel_size_um,\n",
    "                                                  detector_width_pixels):\n",
    "    pixel_size_mm = pixel_size_um / 1000\n",
    "    plate_scale = (206265 * pixel_size_mm) / focal_length_mm\n",
    "    field_of_view = plate_scale * detector_width_pixels\n",
    "    return plate_scale, field_of_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c449fea-0ab0-4976-acad-d866663566eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_scale_for_50mm, field_of_view_for_50mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=focal_lengths_mm[0],\n",
    "                                                                                             pixel_size_um=pixel_size_um,\n",
    "                                                                                             detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "plate_scale_for_75mm, field_of_view_for_75mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=focal_lengths_mm[1],\n",
    "                                                                                             pixel_size_um=pixel_size_um,\n",
    "                                                                                             detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "plate_scale_for_100mm, field_of_view_for_100mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=focal_lengths_mm[3],\n",
    "                                                                                              pixel_size_um=pixel_size_um,\n",
    "                                                                                              detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "print(f\"For {focal_lengths_mm[0]}mm lens, plate scale is {np.round(plate_scale_for_50mm,4)} (arcseconds / pixel) and field of view is {np.round(field_of_view_for_50mm, 4)} (arcseconds).\") \n",
    "print(f\"For {focal_lengths_mm[1]}mm lens, plate scale is {np.round(plate_scale_for_75mm,4)} (arcseconds / pixel) and field of view is {np.round(field_of_view_for_75mm, 4)} (arcseconds).\") \n",
    "print(f\"For {focal_lengths_mm[3]}mm lens, plate scale is {np.round(plate_scale_for_100mm,4)} (arcseconds / pixel) and field of view is {np.round(field_of_view_for_100mm, 4)} (arcseconds).\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b27a96-1993-4cfd-bd82-dbdc8ed39828",
   "metadata": {},
   "source": [
    "### Calculating Diffraction-limit of Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38a90e-66ff-450b-840b-63aa5d1b05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diffraction_limit_arcseconds(wavelength_of_detector_nm, pixel_size_um, detector_width_pixels):\n",
    "    pixel_size_nm = pixel_size_um * 1000 # um to nm\n",
    "    detector_width_nm = detector_width_pixels * pixel_size_nm \n",
    "\n",
    "    diffraction_limit_of_detector_radians = 1.22 * (wavelength_of_detector_nm / detector_width_nm)\n",
    "    diffraction_limit_of_detector_arcseconds = diffraction_limit_of_detector_radians * 206265\n",
    "\n",
    "    return diffraction_limit_of_detector_arcseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7cacc-67dc-48b6-b428-7d09adedcbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffraction_limit_of_detector_arcseconds = calculate_diffraction_limit_arcseconds(wavelength_of_detector_nm=wavelength_of_detector_nm,\n",
    "                                                                                  pixel_size_um=pixel_size_um,\n",
    "                                                                                  detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "print(f\"Diffraction limit: {diffraction_limit_of_detector_arcseconds:.2f} arcseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa0ffa-88df-4cab-98fc-6191e5e2fe84",
   "metadata": {},
   "source": [
    "## 1.2 Field of View\n",
    "*GOAL*: Determine an optimal imaging system that is capable of imaging the entire extent of Jupiter in a single exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9606d6-4163-4aed-aca9-0347584ec19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#height_of_jupiter_cm = \n",
    "#width_of_jupiter_cm =\n",
    "#distance_from_detector_to_jupiter_cm =  \n",
    "#number_of_pixels_to_resolve_jupiter = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48408b-cc4e-433d-9b08-8818adb329a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jupiter_arcseconds(detector_width_pixels,\n",
    "                                 pixel_size_um,\n",
    "                                 size_of_jupiter_cm,\n",
    "                                 distance_from_detector_to_jupiter_cm):\n",
    "\n",
    "    # arcseconds\n",
    "    distance_from_detector_to_jupiter_mm = distance_from_detector_to_jupiter_cm * 10 # cm to mm\n",
    "    size_of_jupiter_mm = size_of_jupiter_cm * 10 # cm to mm\n",
    "    theta_radians = math.atan(size_of_jupiter_mm / distance_from_detector_to_jupiter_mm) #radians\n",
    "    theta_degrees = math.degrees(theta_radians) # degrees \n",
    "    theta_arcseconds = theta_degrees * 3600 # arcseconds\n",
    "                                                           \n",
    "    return theta_arcseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9695d31-9720-4428-bf9c-281921ebb41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "height_of_jupiter_arcseconds = calculate_jupiter_arcseconds(detector_width_pixels=detector_width_pixels,\n",
    "                                                            pixel_size_um=pixel_size_um,\n",
    "                                                            size_of_jupiter_cm=height_of_jupiter_cm,\n",
    "                                                            distance_from_detector_to_jupiter_cm=distance_from_detector_to_jupiter_cm)\n",
    "\n",
    "width_of_jupiter_arcseconds = calculate_jupiter_arcseconds(detector_width_pixels=detector_width_pixels,\n",
    "                                                           pixel_size_um=pixel_size_um,\n",
    "                                                           size_of_jupiter_cm=width_of_jupiter_cm,\n",
    "                                                           distance_from_detector_to_jupiter_cm=distance_from_detector_to_jupiter_cm)\n",
    "\n",
    "print(f\"Height of Jupiter is {np.round(height_of_jupiter_arcseconds,4)} (arcseconds) and width of Jupiter is {np.round(width_of_jupiter_arcseconds,4)} (arcseconds).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b4162-98c7-4a0c-8361-15267d01507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupiter_plate_scale, jupiter_field_of_view = calculate_needed_plate_scale_and_field_of_view(size_of_object_arcseconds=width_of_jupiter_arcseconds,\n",
    "                                                                                            detector_width_pixels=detector_width_pixels,\n",
    "                                                                                            number_of_pixels_to_resolve=number_of_pixels_to_resolve_jupiter)\n",
    "\n",
    "print(f\"Required plate scale for resolving Jupiter is {np.round(jupiter_plate_scale,4)} (arcseconds / pixel).\")\n",
    "print(f\"Field of view corresponding to required plate scale is {np.round(jupiter_field_of_view,4)} (arcseconds).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896d7da-eafb-496a-b09f-6cdffa23dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupiter_plate_scale, jupiter_field_of_view = calculate_needed_plate_scale_and_field_of_view(size_of_object_arcseconds=width_of_jupiter_arcseconds,\n",
    "                                                                                            detector_width_pixels=detector_width_pixels,\n",
    "                                                                                            number_of_pixels_to_resolve=number_of_pixels_to_resolve_jupiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b3393-c974-4b43-9876-f47c8b7c6663",
   "metadata": {},
   "source": [
    "### Combination of Lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a5b6e-0b4a-4901-8c9c-b4000167adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minimum_distance_between_50mm_75mm_cm = \n",
    "#minimum_distance_between_75mm_75mm_cm =\n",
    "#minimum_distance_between_50mm_100mm_cm =\n",
    "#minimum_distance_between_75mm_100mm_cm ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8590cc-a42e-42a0-b109-06e24e9bdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_focal_length_mm(focal_length_1_mm,\n",
    "                             focal_length_2_mm,\n",
    "                             distance_bewteen_lenses_cm):\n",
    "                                 \n",
    "    distance_between_lenses_mm = distance_bewteen_lenses_cm * 10 # mm\n",
    "    \n",
    "    return 1 / ((1 / focal_length_1_mm) + (1 / focal_length_2_mm) - (distance_between_lenses_mm / (focal_length_1_mm * focal_length_2_mm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac6cc3-fa67-4228-a202-917aba3556b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_focal_length_50_75mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[0],\n",
    "                                                         focal_length_2_mm=focal_lengths_mm[1],\n",
    "                                                         distance_bewteen_lenses_cm=minimum_distance_between_50mm_75mm_cm)\n",
    "\n",
    "combined_focal_length_75_75mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[1],\n",
    "                                                         focal_length_2_mm=focal_lengths_mm[2],\n",
    "                                                         distance_bewteen_lenses_cm=minimum_distance_between_75mm_75mm_cm)\n",
    "\n",
    "combined_focal_length_50_100mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[0],\n",
    "                                                          focal_length_2_mm=focal_lengths_mm[3],\n",
    "                                                          distance_bewteen_lenses_cm=minimum_distance_between_50mm_100mm_cm)\n",
    "\n",
    "combined_focal_length_75_100mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[1],\n",
    "                                                          focal_length_2_mm=focal_lengths_mm[3],\n",
    "                                                          distance_bewteen_lenses_cm=minimum_distance_between_75mm_100mm_cm)\n",
    "\n",
    "print(f\"Combined focal length of {np.round(focal_lengths_mm[0],4)} mm lens and {np.round(focal_lengths_mm[1],4)} mm lens is {np.round(combined_focal_length_50_75mm,4)} (mm).\")\n",
    "print(f\"Combined focal length of {np.round(focal_lengths_mm[1],4)} mm lens and {np.round(focal_lengths_mm[2],4)} mm lens is {np.round(combined_focal_length_75_75mm,4)} (mm).\")\n",
    "print(f\"Combined focal length of {np.round(focal_lengths_mm[0],4)} mm lens and {np.round(focal_lengths_mm[3],4)} mm lens is {np.round(combined_focal_length_50_100mm,4)} (mm).\")\n",
    "print(f\"Combined focal length of {np.round(focal_lengths_mm[1],4)} mm lens and {np.round(focal_lengths_mm[3],4)} mm lens is {np.round(combined_focal_length_75_100mm,4)} (mm).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618f35e-d6d4-477a-b522-f2ba22caf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_focal_length_31_75mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[0],\n",
    "                                                          focal_length_2_mm=combined_focal_length_50_75mm,\n",
    "                                                          distance_bewteen_lenses_cm=minimum_distance_between_75mm_75mm_cm)\n",
    "\n",
    "print(f\"Combined focal length of {np.round(combined_focal_length_50_75mm,4)} mm lens and {np.round(focal_lengths_mm[1],4)} mm lens is {np.round(combined_focal_length_31_75mm,4)} (mm).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b86f35-3977-4b37-b8cc-01f8b9e21a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_focal_length_23_100mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[3],\n",
    "                                                           focal_length_2_mm=combined_focal_length_31_75mm,\n",
    "                                                           distance_bewteen_lenses_cm=minimum_distance_between_75mm_100mm_cm)\n",
    "\n",
    "print(f\"Combined focal length of {np.round(combined_focal_length_31_75mm,4)} mm lens and {np.round(focal_lengths_mm[3],4)} mm lens is {np.round(combined_focal_length_23_100mm,4)} (mm).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282013fa-d537-412a-8220-2969ca6ceaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_scale_for_50mm_75mm, field_of_view_width_for_50mm_75mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=combined_focal_length_50_75mm,\n",
    "                                                                                                       pixel_size_um=pixel_size_um,\n",
    "                                                                                                       detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "plate_scale_for_50mm_75mm, field_of_view_height_for_50mm_75mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=combined_focal_length_50_75mm,\n",
    "                                                                                                       pixel_size_um=pixel_size_um,\n",
    "                                                                                                       detector_width_pixels=detector_height_pixels)\n",
    "\n",
    "plate_scale_for_31mm_75mm, field_of_view_for_31mm_75mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=combined_focal_length_31_75mm,\n",
    "                                                                                                       pixel_size_um=pixel_size_um,\n",
    "                                                                                                       detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "plate_scale_for_23mm_100mm, field_of_view_for_23mm_100mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=combined_focal_length_23_100mm,\n",
    "                                                                                                       pixel_size_um=pixel_size_um,\n",
    "                                                                                                       detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "                                                                                                      \n",
    "print(f\"For combining {focal_lengths_mm[0]} mm lens with {focal_lengths_mm[1]} mm lens, plate scale is {np.round(plate_scale_for_50mm_75mm,4)} (arcseconds / pixel) and field of view is {np.round(field_of_view_width_for_50mm_75mm, 4)}x{np.round(field_of_view_height_for_50mm_75mm, 4)} (arcseconds).\")\n",
    "print(f\"For combining {focal_lengths_mm[0]} mm lens with {np.round(combined_focal_length_31_75mm,4)} mm lens, plate scale is {np.round(plate_scale_for_50mm_75mm,4)} (arcseconds / pixel) and field of view is {np.round(field_of_view_for_31mm_75mm, 4)} (arcseconds).\")\n",
    "print(f\"For combining {focal_lengths_mm[0]} mm lens with {np.round(combined_focal_length_23_100mm,4)} mm lens, plate scale is {np.round(plate_scale_for_50mm_75mm,4)} (arcseconds / pixel) and field of view is {np.round(field_of_view_for_23mm_100mm, 4)} (arcseconds).\")\n",
    "\n",
    "                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a8104-9bf3-47a3-99d9-b30ce0604701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_jupiter(focal_length_mm,\n",
    "                        size_of_jupiter_cm,\n",
    "                        size_of_jupiter_arcseconds):\n",
    "\n",
    "    theta_degrees = size_of_jupiter_arcseconds / 3600\n",
    "    distance_to_jupiter_cm = size_of_jupiter_cm / np.tan(theta_degrees)\n",
    "    return distance_to_jupiter_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6feab3-b81d-4ff4-a669-ed47c089422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_distance_to_jupiter_cm = distance_to_jupiter(focal_length_mm=combined_focal_length_23_100mm,\n",
    "                                  size_of_jupiter_cm=width_of_jupiter_cm,\n",
    "                                  size_of_jupiter_arcseconds=width_of_jupiter_arcseconds)\n",
    "\n",
    "print(f\"For combining {focal_lengths_mm[0]} mm lens with {np.round(combined_focal_length_23_100mm,4)} mm lens, the distance to Jupiter is {np.round(smallest_distance_to_jupiter_cm,4)} (cm).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca055102-e3b6-41b4-864a-798852ef35f1",
   "metadata": {},
   "source": [
    "### With Experimental Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe59942-ce37-441f-b72c-306a9d4d56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_between_50mm_75mm_cm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bcb4e-4e93-4115-a1c7-0b8976bb94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_combined_focal_length_50_75mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[0],\n",
    "                                                                focal_length_2_mm=focal_lengths_mm[1],\n",
    "                                                                distance_bewteen_lenses_cm=distance_between_50mm_75mm_cm)\n",
    "\n",
    "print(f\"Actual combined focal length of {np.round(focal_lengths_mm[0],4)} mm lens and {np.round(focal_lengths_mm[1],4)} mm lens is {np.round(actual_combined_focal_length_50_75mm,4)} (mm).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4602da-b91f-4714-820d-33d861c0ff4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual_plate_scale_for_50mm_75mm, actual_field_of_view_for_50mm_75mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=actual_combined_focal_length_50_75mm,\n",
    "                                                                                                                     pixel_size_um=pixel_size_um,\n",
    "                                                                                                                     detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "print(f\"For combining {focal_lengths_mm[0]} mm lens with {focal_lengths_mm[1]} mm lens, the actaul plate scale is {np.round(actual_plate_scale_for_50mm_75mm,4)} (arcseconds / pixel) and actual field of view is {np.round(actual_field_of_view_for_50mm_75mm, 4)} (arcseconds).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a6e70-e5ad-4834-ab6e-7f9c7b624c4c",
   "metadata": {},
   "source": [
    "## 1.3 Field of View & Plate Scale\n",
    "What is the plate scale achieved with your optical system that imaged the entire extent of Jupiter? What plate scale should be used to resolve Jupiter spots and smallest strucutres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77487f08-a76c-4d3b-a59b-33290b985b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_of_jupiter_small_spot_cm = \n",
    "#number_of_pixels_to_resolve_jupiter_small_spot = \n",
    "#distance_from_detector_to_jupiter_small_spot_cm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc4c61-1756-40ca-86de-48ebc316e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_jupiter_small_spot_arcseconds = calculate_jupiter_arcseconds(detector_width_pixels=detector_width_pixels,\n",
    "                                                                     pixel_size_um=pixel_size_um,\n",
    "                                                                     size_of_jupiter_cm=size_of_jupiter_small_spot_cm,\n",
    "                                                                     distance_from_detector_to_jupiter_cm=distance_from_detector_to_jupiter_small_spot_cm)\n",
    "\n",
    "print(f\"Size of Jupiter's small spot is {np.round(size_of_jupiter_small_spot_arcseconds,4)} (arcseconds).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a01536-a913-4427-bfe3-20c2995a06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupiter_small_spot_plate_scale, jupiter_small_spot_field_of_view = calculate_needed_plate_scale_and_field_of_view(size_of_object_arcseconds=size_of_jupiter_small_spot_arcseconds,\n",
    "                                                                                                                  detector_width_pixels=detector_width_pixels,\n",
    "                                                                                                                  number_of_pixels_to_resolve=number_of_pixels_to_resolve_jupiter_small_spot)\n",
    "\n",
    "print(f\"Required plate scale for resolving Jupiter's small spot is {np.round(jupiter_small_spot_plate_scale,4)} (arcseconds / pixel).\")\n",
    "print(f\"Field of view corresponding to required plate scale is {np.round(jupiter_small_spot_field_of_view,4)} (arcseconds).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce813a-a50e-4740-80b3-1caff341f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance_between_50mm_75mm_cm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54685d4-224b-461f-8a87-e932cf037195",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_spot_combined_focal_length_50_75mm = combined_focal_length_mm(focal_length_1_mm=focal_lengths_mm[0],\n",
    "                                                                    focal_length_2_mm=focal_lengths_mm[1],\n",
    "                                                                    distance_bewteen_lenses_cm=distance_between_50mm_75mm_cm)\n",
    "\n",
    "print(f\"Actual combined focal length of {np.round(focal_lengths_mm[0],4)} mm lens and {np.round(focal_lengths_mm[1],4)} mm lens is {np.round(small_spot_combined_focal_length_50_75mm,4)} (mm).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19430b88-329c-4673-8a6c-2578678bf4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_spot_plate_scale_for_50mm_75mm, small_spot_field_of_view_for_50mm_75mm = calculate_given_plate_scale_and_field_of_view(focal_length_mm=small_spot_combined_focal_length_50_75mm,\n",
    "                                                                                                                             pixel_size_um=pixel_size_um,\n",
    "                                                                                                                             detector_width_pixels=detector_width_pixels)\n",
    "\n",
    "print(f\"For combining {focal_lengths_mm[0]} mm lens with {focal_lengths_mm[1]} mm lens, the actaul plate scale is {np.round(small_spot_plate_scale_for_50mm_75mm,4)} (arcseconds / pixel) and actual field of view is {np.round(small_spot_field_of_view_for_50mm_75mm, 4)} (arcseconds).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459dded7-678d-469f-881b-192890f5ac9e",
   "metadata": {},
   "source": [
    "# Detector Properties\n",
    "\n",
    "**KEY STEPS:**\n",
    "- **Determine the noise characteristics of your detector.**\n",
    "- **What is the detector’s read noise, dark current, and bias level?** \n",
    "\n",
    "Photons cannot be necessarily measured directly, therefore, a dector senses photons and produces an electrical signal which in turn can be measured. \n",
    "- Electrical signal (discretized (digital) units of analog-digital units (ADU)) (counts)\n",
    "The number of counts detected in a pixel will be proportional to the number of photons that landed in the pixel!\n",
    "\n",
    "$$\n",
    "\\text{gain} * \\text{analog-digital units} = \\text{number of photons}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07035d-06ae-44e4-833c-e86a376e0f8c",
   "metadata": {},
   "source": [
    "### RAW to FITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cea69-1f36-4d7a-a9ef-89b3e8416df2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Turn RAW file into FITS file\n",
    "def raw_to_fits(raw_file, shape=(1080, 1440), destination=None, ADC_bits=12, simu_artifacts=False):\n",
    "    \"\"\"\n",
    "    Converts a RAW file to a FITS formatted image.\n",
    "\n",
    "    Inputs:\n",
    "    - raw_file (string): the file path of the RAW image.\n",
    "    - shape (tuple): a tuple with (# of rows, # of columns) for the image dimensions.\n",
    "    - destination (string): the output filename for the FITS image. If None, \n",
    "                            the '.raw' extension will be replaced with '.fits'.\n",
    "    - ADC_bits (integer): the bit depth of the analog-to-digital conversion.\n",
    "    - simu_artifcats (bool): whether to simulate artifcats (hot pixels, flat field, etc).\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the exposure time (in seconds) from the filename by splitting on 'us.raw'\n",
    "    # and then converting\n",
    "    integration_time = float(raw_file.split(\"us.raw\")[0].split(\"_\")[-1]) / 1e6\n",
    "\n",
    "    # Get the number of rows and columns from the shape input\n",
    "    number_of_rows, number_of_columns = shape\n",
    "\n",
    "    # Open the raw file in binary mode ('rb') and read its contents into raw_img\n",
    "    with open(raw_file, 'rb') as raw:\n",
    "        raw_img = raw.read()\n",
    "\n",
    "    # Check the file size to determine whether the file is 8-bit or 16-bit\n",
    "    filesize = len(raw_img)\n",
    "    if filesize == number_of_rows * number_of_columns: # 8-bit image\n",
    "        size = 'B' # 'B' represents unsigned 8-bit integers\n",
    "        file_bits = 8\n",
    "    elif filesize == number_of_rows * number_of_columns * 2: # 16-bit image\n",
    "        size = 'H'\n",
    "        file_bits = 16\n",
    "    else:\n",
    "        # If the filesize doesn't match the expected size, raise an error\n",
    "        raise ValueError(\"The image shape provided does not match the length of the file\")\n",
    "\n",
    "    # Create a format string for struct.unpack to interpret the binary data\n",
    "    # '<' for little-endian or 'H' for 8-bit or 16-bit\n",
    "    format_string = f\"<{number_of_rows*number_of_columns}{size}\" \n",
    "    \n",
    "    # Unpack the binary data into a flat numpy array, then reshape it \n",
    "    #to match the image dimension\n",
    "    byte_array = np.array(struct.unpack(format_string, raw_img)).reshape(number_of_rows, number_of_columns)\n",
    "\n",
    "    # Scale the image if the file bit depth is greater than the ADC bit depth\n",
    "    if file_bits > ADC_bits:\n",
    "        byte_array = byte_array / 2**(file_bits - ADC_bits)\n",
    "\n",
    "    # If simulation of artifcats is enabled, perform several modifications to the image\n",
    "    if simu_artifacts:\n",
    "        ny, nx = byte_array.shape # Get the image dimensions\n",
    "\n",
    "        dark_current = 1.25 # Dark current in (ADU/s)\n",
    "        byte_array += dark_current * integration_time # Add dark current over the exoposure time\n",
    "\n",
    "        # Create a flat-field correction (simulating non-uniform response across the sensor)\n",
    "        x_grid, y_grid = np.meshgrid(np.arange(nx), np.arange(ny)) # Create a grid of coordinates\n",
    "        flat_field = np.exp(-0.5 * ((x_grid - nx // 2) ** 2 / (3 * nx) ** 2 + (y_grid - ny // 2) ** 2 / (3 * ny) ** 2))\n",
    "        byte_array *= flat_field # Apply the flat-field correction by multiplying\n",
    "\n",
    "        # Save current random state and seed it to generate reproducible results for hot and cold pixels\n",
    "        state = np.random.get_state()\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # Simulate hot pixels (bright pixels due to sensor noise)\n",
    "        hot_pixel_indices = np.random.randint(0, high=nx * ny - 1, size=int(0.01 * nx * ny))  # Random indices for hot pixels\n",
    "        hot_pixel_indices = np.unravel_index(hot_pixel_indices, (ny, nx))  # Convert flat indices to 2D indices\n",
    "\n",
    "        # Amplify hot pixels based on a Gaussian distribution and exposure time\n",
    "        byte_array[hot_pix_indices] *= tint * np.clip(30 * np.random.randn(int(0.01 * nx * ny)), dark_current, 2 ** ADC_bits)\n",
    "\n",
    "        # Simulate cold pixels (dim pixels)\n",
    "        cold_pix_indices = np.random.randint(0, high=nx * ny - 1, size=int(0.01 * nx * ny))  # Random indices for cold pixels\n",
    "        cold_pix_indices = np.unravel_index(cold_pix_indices, (ny, nx))  # Convert flat indices to 2D indices\n",
    "        byte_array[cold_pix_indices] *= np.random.uniform(0, 0.5, size=int(0.01 * nx * ny))  # Dim cold pixels\n",
    "\n",
    "        # Restore the random state to ensure that random processes elsewhere in the code remain unaffected\n",
    "        np.random.set_state(state)\n",
    "\n",
    "        # Add a constant bias value to the entire image\n",
    "        byte_array += 64  # Bias offset in ADU\n",
    "\n",
    "        # Add Gaussian read noise to the image (random noise due to sensor readout)\n",
    "        readnoise = 3  # Read noise level in ADU\n",
    "        byte_array += readnoise * np.random.randn(ny, nx)  # Add noise to each pixel\n",
    "\n",
    "        # Clip the values to ensure they remain within the range of the ADC bits\n",
    "        byte_array = np.clip(byte_array, 0, 2 ** ADC_bits)\n",
    "\n",
    "    # Determine the ouput FITS filename\n",
    "    if destination is None:\n",
    "        # Replace the .raw extension with .fits if no specific destination is provided\n",
    "        fits_file = raw_file.replace('.raw', '.fits')\n",
    "    else:\n",
    "        # Use the specified destination filename\n",
    "        fits_file = destination\n",
    "\n",
    "    # If simulation of artifacts was enabled, append \"_simu\" to the filename\n",
    "    if simu_artifacts:\n",
    "        fits_file = fits_file.replace(\".fits\", \"_simu.fits\")\n",
    "\n",
    "    # Create a FITS file from the numpy array\n",
    "    hdu = fits.PrimaryHDU(byte_array)  # Create a primary HDU object (Header Data Unit)\n",
    "    hdu.writeto(fits_file, overwrite=True)  # Write the FITS file to disk, overwriting if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3f11e-b4c7-4136-8dcf-97fa44b7d97c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Loop through all RAW files in given directory\n",
    "def process_raw_to_fits(raw_directory, fits_directory, shape=(1080, 1440)):\n",
    "    # Get a list of all .raw files in the directory\n",
    "    raw_files = glob.glob(os.path.join(raw_directory, \"*.raw\"))\n",
    "    print(\"Found raw files:\\n\", raw_files)\n",
    "\n",
    "    # Make sure output directory exists\n",
    "    if not os.path.exists(fits_directory):\n",
    "        os.makedirs(fits_directory)\n",
    "    \n",
    "    print(\"Found output directory:\\n\", fits_directory)\n",
    "\n",
    "    # Loop through each file and process it\n",
    "    for raw_file in raw_files:\n",
    "        # Determine the ouputs FITS filename\n",
    "        fits_filename = raw_file.replace(\".raw\", \".fits\")\n",
    "\n",
    "        # Check if the FITS file already exists\n",
    "        if len(glob.glob(fits_filename)) >= 1:\n",
    "            print(f\"FITS file {fits_filename} already exists. Skipping {fits_filename}.\")\n",
    "            continue\n",
    "\n",
    "        # Convert raw file to FITS\n",
    "        #print(f\"Converting {raw_file} to FITS format...\") # Extra\n",
    "        raw_to_fits(raw_file, shape=(1080, 1440))\n",
    "        #print(f\"Conversion completed for {raw_file}.\") # Extra\n",
    "\n",
    "        # Move the FITS file to the fits directory\n",
    "        new_fits_path = os.path.join(fits_directory, os.path.basename(fits_filename))\n",
    "        shutil.move(fits_filename, new_fits_path)\n",
    "        print(f\"Moved {fits_filename} to {new_fits_path}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ef5ae-48e3-4f19-982b-8823d4b44e79",
   "metadata": {},
   "source": [
    "## 2.1 Bias & Dark Current\n",
    "\n",
    "*GOAL:* Report the bias level and dark current level for your camera.\n",
    "\n",
    "**Bias level:** signal recorded by the output amplifier even when there is no illumination, can vary from pixel to pixel\n",
    "- To measure the bias level, one needs to take dark frames with very short integration times.\n",
    "\n",
    "\n",
    "**Dark current:** thermal effects that promote charges from the valence band to the conduction band, where they are stored and read out (unwanted e- are confused for photoelectrons)\n",
    "- To measure the dark current, one needs to take dark frames with different exopsure times.\n",
    "\n",
    "## 2.1.1 Bias Level Estimation from Dark Frames (short exposure)\n",
    "*GOAL:* Collect a stack of dark frames and examine the mean signal and the error on the mean signal to estimate the bias level. \n",
    "- Plot histograms of the signal levels (or a histogram of the mean signal for each pixel in the image).\n",
    "- Report the resulting bias level for your camera. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903f241-5a18-4392-8dd9-bac71ae1032a",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a8b39-91de-44e4-aecf-3823bd833645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIAS: RAW and FITS directories\n",
    "# Trial 1\n",
    "#raw_bias_directory = \n",
    "#fits_bias_directory =\n",
    "\n",
    "# Trial 2\n",
    "#raw_bias_directory2 = \n",
    "#fits_bias_directory2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2821dfe-8ae6-4bf9-8bd8-a4310c4bf6b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# BIAS: Convert RAW to FITS\n",
    "process_raw_to_fits(raw_directory=raw_bias_directory,\n",
    "                    fits_directory=fits_bias_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_bias_directory2,\n",
    "                    fits_directory=fits_bias_directory2,\n",
    "                    shape=(1080, 1440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66425581-44b0-49d2-aa56-570f9942500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open one of the FITS files to check its shape\n",
    "with fits.open(\"bias/trial_1/5us/fits/dark_frame1_5us.fits\") as hdul:\n",
    "    data = hdul[0].data # Extract the image data\n",
    "    data_shape = data.shape # Get the shape of the image data\n",
    "\n",
    "print(f\"The shape of the FITS file data is {data_shape}.\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa0d67-6643-44c7-b7e1-6fab847e6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all FITS bias files in the directory for processing\n",
    "fits_bias_files1 = glob.glob(os.path.join(fits_bias_directory, \"*.fits\"))\n",
    "fits_bias_files2 = glob.glob(os.path.join(fits_bias_directory2, \"*.fits\"))\n",
    "\n",
    "fits_bias_files = fits_bias_files1 + fits_bias_files2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53195a75-4b10-4e8b-850f-4a2f278633e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verify that FITS files are found\n",
    "print(f\"Number of FITS files found: {len(fits_bias_files)}\")\n",
    "print(\"FITS files:\", fits_bias_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543c62e-ce98-471a-9eca-c1c455e3e8b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Single File: Histogram of Non-zero Pixel Signal Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f6861-28eb-4b5f-b923-e76d0ccb9f7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the indices where the signal level is non-zero (excluding empty pixels)\n",
    "non_zero_signal_indices = np.argwhere(data != 0)\n",
    "non_zero_signal_values = data[data != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfefb55-7417-4472-9d74-d339435e3f92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create pixel indices for the x-axis (each pixel has a corresponding index)\n",
    "pixel_indices = np.arange(len(non_zero_signal_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7ea16-3ad0-4579-8a2b-7a301af4408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot to visualize the signal levels for non-zero pixels\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(pixel_indices, non_zero_signal_values, color='blue')\n",
    "plt.title('Single FILE: Bar Plot of Non-zero Pixel Signal Levels')\n",
    "plt.xlabel('Pixel (Index)')\n",
    "plt.ylabel('Signal Level (ADU)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1cfda-5c08-457c-bd3c-2ce0807f09be",
   "metadata": {},
   "source": [
    "### Single: Flatten Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0126d-62c2-43c8-a8f8-6c88d3fc8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 2D image data into a 1D array\n",
    "flattened_one_data = data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4061b41-caa0-40a5-9e4b-8453472ea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm proper flattening\n",
    "print(f\"Shape of original data: {data.shape}\")\n",
    "print(f\"Shape of flattened data: {flattened_one_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e33b6-76b6-4dda-8c6e-405cae2d5a06",
   "metadata": {},
   "source": [
    "### Single File: Histrogram of Signal Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a5366-ae31-453f-9b75-f380f3fa27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique signal levels\n",
    "unique_signal_levels = np.unique(flattened_one_data)\n",
    "print(f\"Unique signal levels: {unique_signal_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e22c11-b372-4026-90e6-26713b24e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom bin edges to match the unique signal levels for the histogram\n",
    "# This ensures that each unique signal level gets its own bin\n",
    "bin_edges = np.concatenate(([unique_signal_levels[0] - 0.5], \n",
    "                            (unique_signal_levels[:-1] + unique_signal_levels[1:]) / 2,\n",
    "                            [unique_signal_levels[-1] + 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef422e7d-50d2-4700-bccb-c50759bcf259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram using the custom bins to visualize the distribution of signal levels\n",
    "plt.figure()\n",
    "plt.hist(flattened_one_data, bins=bin_edges, color='blue', alpha=0.7)\n",
    "plt.title(\"Histogram of Signal Levels\")\n",
    "plt.xlabel(\"Signal Level (ADU)\")\n",
    "plt.ylabel(\"Number of Pixels (n)\")\n",
    "plt.xticks(unique_signal_levels)  # Set x-axis ticks to show only the unique values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49428ec-f83f-4553-a6db-f204205f3842",
   "metadata": {},
   "source": [
    "### Multiple Files: Histogram of Non-zero Pixel Signal Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df81765-5e0e-4ec0-bd6e-38b00e523012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to accumulate the sum of pixel values across files\n",
    "sum_signal = None\n",
    "num_files = len(fits_bias_files)  # Number of FITS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c0524-6ddd-4314-96e4-c4e96e04da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each FITS file and sum the pixel values\n",
    "for fits_bias_file in fits_bias_files:\n",
    "    with fits.open(fits_bias_file) as hdul:\n",
    "        data = hdul[0].data  # Load the data from the FITS file\n",
    "\n",
    "        if sum_signal is None:\n",
    "            # Initialize sum_signal array with zeros, same shape as the data\n",
    "            sum_signal = np.zeros_like(data)\n",
    "\n",
    "        # Add current file's data to the cumulative sum\n",
    "        sum_signal += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef3183-e532-49e2-9eaf-c5cf1d937911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean signal level for each pixel by dividing by the number of files\n",
    "mean_signal = sum_signal / num_files\n",
    "\n",
    "# Select non-zero mean signal values for visualization\n",
    "non_zero_signal_values = mean_signal[mean_signal != 0]\n",
    "\n",
    "# Generate pixel indices for plotting (x-axis)\n",
    "pixel_indices = np.arange(len(non_zero_signal_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d8108-1f76-497d-bc83-03db2df93b2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot for the mean signal levels across all FITS files (non-zero pixels only)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(pixel_indices, non_zero_signal_values, color='blue')\n",
    "plt.title('Mean Signal Levels of Non-Zero Pixels Across FITS Files')\n",
    "plt.xlabel('Pixel (Index)')\n",
    "plt.ylabel('Mean Signal Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265fcbe-cb8c-4953-9ee4-efd69693b077",
   "metadata": {},
   "source": [
    "### Multiple Files: Histrogram of Signal Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0beb24c-ff56-48f8-a093-8eeacb1c30e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the 2D mean signal array to a 1D array for histogram plotting\n",
    "flattened_mean_signal = mean_signal.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c2d5c-67d7-4764-975e-62b6d15032b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get the unique signal levels in the flattened mean signal array\n",
    "unique_mean_signal_levels = np.unique(flattened_mean_signal)\n",
    "print(f\"Unique mean signal levels: {unique_mean_signal_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ded65-8fdf-4dc0-a227-e3ddffc8d14c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create custom bin edges to match the unique mean signal levels for the histogram\n",
    "bin_edges_mean_signal = np.concatenate(([unique_mean_signal_levels[0] - 0.5], \n",
    "                                        (unique_mean_signal_levels[:-1] + unique_mean_signal_levels[1:]) / 2,\n",
    "                                        [unique_mean_signal_levels[-1] + 0.5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3b508-0cff-4299-b5d5-f83e732da435",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot the histogram for the mean signal across all files\n",
    "plt.figure()\n",
    "plt.hist(flattened_mean_signal, bins=bin_edges_mean_signal, color='blue', alpha=0.7)\n",
    "plt.title(\"Histogram of Mean Signal Levels Across Multiple Files\")\n",
    "plt.xlabel(\"Mean Signal Level\")\n",
    "plt.ylabel(\"Number of Pixels\")\n",
    "plt.xticks(unique_mean_signal_levels)  # Ensure the x-axis shows the unique values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa05bf-3517-4d78-a454-af79c1627aa8",
   "metadata": {},
   "source": [
    "### Print Bias Level Estimate from Dark Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635dcf81-c65a-4ab3-b54a-ee6ec37eccf9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the overall bias level (average of the mean signals across all pixels)\n",
    "bias_level = np.mean(mean_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686a016-f712-46fd-b3c9-2e0cdf470af9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the mean signal across pixels (to quantify spread)\n",
    "std_dev_signal = np.std(mean_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbd6cf-5027-4c9f-9aa5-d8662779dd21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the error on the bias level (standard error of the mean)\n",
    "# This gives an estimate of how much the mean signal is expected to vary\n",
    "error_on_mean = std_dev_signal / np.sqrt(mean_signal.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b9a41-bb6f-4678-b40c-6e7f542c4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the calculated bias level and the error on the mean\n",
    "print(f\"Bias Level (mean signal): {bias_level}\")\n",
    "print(f\"Error on Bias Level: {error_on_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281103e-744f-430e-b8c8-fb4a65c9780a",
   "metadata": {},
   "source": [
    "## 2.1.2 Dark Current Estimate from Multiple Dark Frames (long exposures)\n",
    "*GOAL:* Collect a stack of dark frames with different exposure times. Examine the mean signal and the error on the mean signal to estimate the dark current. \n",
    "- Measure the signal as a function of exposure time (the slope of your line) and the uncertainty on that slope.\n",
    "- Report this dark current level for your camera. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216f637-6290-4509-b337-577987318473",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047c6fd-451e-490a-bd27-75e89356a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DARK CURRENT: RAW and FITS directories (Trial 1)\n",
    "#raw_dark_current_1s_directory = \n",
    "#fits_dark_current_1s_directory =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76134b-cb5d-4358-8eea-92345ca9c6f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DARK CURRENT: RAW and FITS directories (Trial 2)\n",
    "raw_dark_current_1s_directory2 = \"dark_current/trial2/1s/raw\"\n",
    "fits_dark_current_1s_directory2 = \"dark_current/trial2/1s/fits\"\n",
    "\n",
    "raw_dark_current_5s_directory2 = \"dark_current/trial2/5s/raw\"\n",
    "fits_dark_current_5s_directory2 = \"dark_current/trial2/5s/fits\"\n",
    "\n",
    "raw_dark_current_10s_directory2 = \"dark_current/trial2/10s/raw\"\n",
    "fits_dark_current_10s_directory2 = \"dark_current/trial2/10s/fits\"\n",
    "\n",
    "raw_dark_current_15s_directory2 = \"dark_current/trial2/15s/raw\"\n",
    "fits_dark_current_15s_directory2 = \"dark_current/trial2/15s/fits\"\n",
    "\n",
    "raw_dark_current_20s_directory2 = \"dark_current/trial2/20s/raw\"\n",
    "fits_dark_current_20s_directory2 = \"dark_current/trial2/20s/fits\"\n",
    "\n",
    "raw_dark_current_25s_directory2 = \"dark_current/trial2/25s/raw\"\n",
    "fits_dark_current_25s_directory2 = \"dark_current/trial2/25s/fits\"\n",
    "\n",
    "raw_dark_current_30s_directory2 = \"dark_current/trial2/30s/raw\"\n",
    "fits_dark_current_30s_directory2 = \"dark_current/trial2/30s/fits\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88256ffb-8b63-4d97-bb12-e9c65e8979fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DARK CURRENT: Convert RAW to FITS (Trial 1)\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_1s_directory,\n",
    "                    fits_directory=fits_dark_current_1s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_5s_directory,\n",
    "                    fits_directory=fits_dark_current_5s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_10s_directory,\n",
    "                    fits_directory=fits_dark_current_10s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_15s_directory,\n",
    "                    fits_directory=fits_dark_current_15s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_20s_directory,\n",
    "                    fits_directory=fits_dark_current_20s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_25s_directory,\n",
    "                    fits_directory=fits_dark_current_25s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_30s_directory,\n",
    "                    fits_directory=fits_dark_current_30s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0b592-87a2-49b9-ace5-ae759ba0f9da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DARK CURRENT: Convert RAW to FITS (Trial 2)\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_1s_directory2,\n",
    "                    fits_directory=fits_dark_current_1s_directory2,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_5s_directory2,\n",
    "                    fits_directory=fits_dark_current_5s_directory2,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_10s_directory2,\n",
    "                    fits_directory=fits_dark_current_10s_directory2,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_15s_directory2,\n",
    "                    fits_directory=fits_dark_current_15s_directory2,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_20s_directory2,\n",
    "                    fits_directory=fits_dark_current_20s_directory2,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_25s_directory2,\n",
    "                    fits_directory=fits_dark_current_25s_directory2,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_dark_current_30s_directory2,\n",
    "                    fits_directory=fits_dark_current_30s_directory2,\n",
    "                    shape=(1080, 1440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d342f69-70b3-42a9-bda6-ba0d16166189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all FITS files for different exposure times\n",
    "# This is done by globbing all .fits files in the respective directories\n",
    "exposure_1000000us = glob.glob(os.path.join(fits_dark_current_1s_directory, \"*.fits\"))\n",
    "exposure_5000000us = glob.glob(os.path.join(fits_dark_current_5s_directory, \"*.fits\"))\n",
    "exposure_10000000us = glob.glob(os.path.join(fits_dark_current_10s_directory, \"*.fits\"))\n",
    "exposure_15000000us = glob.glob(os.path.join(fits_dark_current_15s_directory, \"*.fits\"))\n",
    "exposure_20000000us = glob.glob(os.path.join(fits_dark_current_20s_directory, \"*.fits\"))\n",
    "exposure_25000000us = glob.glob(os.path.join(fits_dark_current_25s_directory, \"*.fits\"))\n",
    "exposure_30000000us = glob.glob(os.path.join(fits_dark_current_30s_directory, \"*.fits\"))\n",
    "\n",
    "exposure2_1000000us = glob.glob(os.path.join(fits_dark_current_1s_directory2, \"*.fits\"))\n",
    "exposure2_5000000us = glob.glob(os.path.join(fits_dark_current_5s_directory2, \"*.fits\"))\n",
    "exposure2_10000000us = glob.glob(os.path.join(fits_dark_current_10s_directory2, \"*.fits\"))\n",
    "exposure2_15000000us = glob.glob(os.path.join(fits_dark_current_15s_directory2, \"*.fits\"))\n",
    "exposure2_20000000us = glob.glob(os.path.join(fits_dark_current_20s_directory2, \"*.fits\"))\n",
    "exposure2_25000000us = glob.glob(os.path.join(fits_dark_current_25s_directory2, \"*.fits\"))\n",
    "exposure2_30000000us = glob.glob(os.path.join(fits_dark_current_30s_directory2, \"*.fits\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01434478-8cfb-4793-bbb4-67ea37993db1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to map exposure times to the list of files for easier access\n",
    "exposure_files_dict = {\n",
    "    \"exposure_1000000us\": exposure_1000000us,\n",
    "    \"exposure_5000000us\": exposure_5000000us,\n",
    "    \"exposure_10000000us\": exposure_10000000us,\n",
    "    \"exposure_15000000us\": exposure_15000000us,\n",
    "    \"exposure_20000000us\": exposure_20000000us,\n",
    "    \"exposure_25000000us\": exposure_25000000us,\n",
    "    \"exposure_30000000us\": exposure_30000000us,\n",
    "    \"exposure2_1000000us\": exposure2_1000000us,\n",
    "    \"exposure2_5000000us\": exposure2_5000000us,\n",
    "    \"exposure2_10000000us\": exposure2_10000000us,\n",
    "    \"exposure2_15000000us\": exposure2_15000000us,\n",
    "    \"exposure2_20000000us\": exposure2_20000000us,\n",
    "    \"exposure2_25000000us\": exposure2_25000000us,\n",
    "    \"exposure2_30000000us\": exposure2_30000000us,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c95e1-5973-437d-b1b5-8f377fb95061",
   "metadata": {},
   "source": [
    "### Plotting Mean Signal vs. Exposure Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02826934-840e-4fd3-904b-e7ac3af6cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Signal Calculation Function\n",
    "def calculate_mean_signal(filenames):\n",
    "    \"\"\"\n",
    "    Calculate the mean signal from a set of FITS files.\n",
    "    This function reads multiple files of the same exposure and calculates\n",
    "    the average signal for the entire frame.\n",
    "    \"\"\"\n",
    "    signals = []\n",
    "    for filename in filenames:\n",
    "        with fits.open(filename) as hdul:\n",
    "            data = hdul[0].data  # Load the FITS file data\n",
    "            signals.append(np.mean(data))  # Append the mean signal of the current frame\n",
    "    return np.mean(signals)  # Return the average signal across all files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9a46c-2e2e-446a-8c46-82d79b69149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark Current Processing Function\n",
    "def process_dark_current(exposure_files_dict):\n",
    "    \"\"\"\n",
    "    Process dark current data by calculating the mean signal for each exposure time.\n",
    "    Perform linear regression to estimate the dark current (slope) and its uncertainty.\n",
    "    \"\"\"\n",
    "    exposure_times = []  # To store the exposure times (in seconds)\n",
    "    mean_signals = []    # To store the mean signal for each exposure time\n",
    "    \n",
    "    for key, files in exposure_files_dict.items():\n",
    "        # Extract the numeric exposure time from the dictionary key (in microseconds)\n",
    "        exposure_time_str = key.split('_')[1].replace('us', '')  # Extract the numeric part in us\n",
    "        exposure_time = int(exposure_time_str) / 1e6  # Convert exposure time to seconds\n",
    "        exposure_times.append(exposure_time)  # Append to the exposure time list\n",
    "        \n",
    "        # Calculate the mean signal for the given set of files\n",
    "        mean_signal = calculate_mean_signal(files)\n",
    "        mean_signals.append(mean_signal)  # Append the calculated mean signal\n",
    "    \n",
    "    # Convert exposure_times and mean_signals to numpy arrays for further processing\n",
    "    exposure_times = np.array(exposure_times, dtype=np.float64)\n",
    "    mean_signals = np.array(mean_signals, dtype=np.float64)\n",
    "\n",
    "    # ## Linear Regression to Estimate Dark Current (Slope)\n",
    "    \n",
    "    # Perform linear regression to get the slope (dark current), intercept, and error values\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(exposure_times, mean_signals)\n",
    "\n",
    "    # Return the results for further use (such as plotting or reporting)\n",
    "    return exposure_times, mean_signals, slope, intercept, std_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490ea0d-c52e-4f07-b091-7749f51ef827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark Current Calculation\n",
    "# Process the dark current data using the function defined above\n",
    "exposure_times, mean_signals, slope, intercept, std_err = process_dark_current(exposure_files_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1830b-fd8f-47d4-a98b-4dad205ea260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Mean Signal vs Exposure Time\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(exposure_times, mean_signals, label=\"Mean Signal\")  # Scatter plot of exposure time vs mean signal\n",
    "plt.plot(exposure_times, intercept + slope * exposure_times, 'r--', \n",
    "         label=f\"Fit: Slope={slope:.4f}, Intercept={intercept:.2f}\")  # Plot the linear fit line\n",
    "plt.xlabel(\"Exposure Time (s)\")  # X-axis label\n",
    "plt.ylabel(\"Mean Signal (ADU)\")  # Y-axis label\n",
    "plt.title(\"Mean Signal vs Exposure Time\")  # Plot title\n",
    "plt.legend()  # Show legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfeaf36-f23b-4750-87d2-b5c647a66880",
   "metadata": {},
   "source": [
    "### Print Dark Current Estimate from Dark Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69337c39-c492-4f0b-9009-bfb9c48573d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the estimated dark current (slope) and the uncertainty (standard error)\n",
    "print(f\"Dark Current (Slope): {np.round(slope, 4)} ADU/s\")\n",
    "print(f\"Uncertainty in Dark Current (Slope): {np.round(std_err, 4)} ADU/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603f93e-7c36-4678-ae02-f3d7b47ab115",
   "metadata": {},
   "source": [
    "## 2.2 Read Noise Estimate from Multiple Flat Frames (short & long exposures)\n",
    "*GOAL:* Measure images of a white light \"flat frame\" source at different intensities. Analyze a stack of flat frames to measure the read noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66f0d2-1d6c-403d-b9f2-8b02f579883f",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0999e96-5910-42a9-b984-0670b5d042d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ NOISE: RAW and FITS directories\n",
    "#raw_readnoise_5us_directory = \n",
    "#fits_readnoise_5us_directory =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caafe87-1846-4ecd-a599-72ad086bfd6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# READ NOISE: Convert RAW to FITS\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_5us_directory,\n",
    "                    fits_directory=fits_readnoise_5us_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_50us_directory,\n",
    "                    fits_directory=fits_readnoise_50us_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_500us_directory,\n",
    "                    fits_directory=fits_readnoise_500us_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_5000us_directory,\n",
    "                    fits_directory=fits_readnoise_5000us_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_05s_directory,\n",
    "                    fits_directory=fits_readnoise_05s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_1s_directory,\n",
    "                    fits_directory=fits_readnoise_1s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_5s_directory,\n",
    "                    fits_directory=fits_readnoise_5s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_10s_directory,\n",
    "                    fits_directory=fits_readnoise_10s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_15s_directory,\n",
    "                    fits_directory=fits_readnoise_15s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_20s_directory,\n",
    "                    fits_directory=fits_readnoise_20s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_25s_directory,\n",
    "                    fits_directory=fits_readnoise_25s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_readnoise_30s_directory,\n",
    "                    fits_directory=fits_readnoise_30s_directory,\n",
    "                    shape=(1080, 1440))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98014247-3d51-4901-b109-5953f77d7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all FITS files for different exposure times\n",
    "flat_5us = glob.glob(os.path.join(fits_readnoise_5us_directory, \"*.fits\"))\n",
    "flat_50us = glob.glob(os.path.join(fits_readnoise_50us_directory, \"*.fits\"))\n",
    "flat_500us = glob.glob(os.path.join(fits_readnoise_500us_directory, \"*.fits\"))\n",
    "flat_5000us = glob.glob(os.path.join(fits_readnoise_5000us_directory, \"*.fits\"))\n",
    "flat_500000us = glob.glob(os.path.join(fits_readnoise_05s_directory, \"*.fits\"))\n",
    "flat_1000000us = glob.glob(os.path.join(fits_readnoise_1s_directory, \"*.fits\"))\n",
    "flat_5000000us = glob.glob(os.path.join(fits_readnoise_5s_directory, \"*.fits\"))                        \n",
    "flat_10000000us = glob.glob(os.path.join(fits_readnoise_10s_directory, \"*.fits\"))                        \n",
    "flat_15000000us = glob.glob(os.path.join(fits_readnoise_15s_directory, \"*.fits\"))                       \n",
    "flat_20000000us = glob.glob(os.path.join(fits_readnoise_20s_directory, \"*.fits\"))                        \n",
    "flat_25000000us = glob.glob(os.path.join(fits_readnoise_25s_directory, \"*.fits\"))                        \n",
    "flat_30000000us = glob.glob(os.path.join(fits_readnoise_30s_directory, \"*.fits\"))                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9da513-dc3b-4f85-8227-678133efc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map exposure times to the list of files for easier access\n",
    "flat_files_dict = {\n",
    "    \"500000us\": flat_500000us,\n",
    "    \"1000000us\": flat_1000000us,\n",
    "    \"5000000us\": flat_5000000us,\n",
    "    \"10000000us\": flat_10000000us,\n",
    "    \"15000000us\": flat_15000000us,\n",
    "    \"20000000us\": flat_20000000us,\n",
    "    \"25000000us\": flat_25000000us,\n",
    "    \"30000000us\": flat_30000000us,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adfb29-6aa3-4f66-8008-215c39da7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for only short exposure times\n",
    "\n",
    "flat_files_dict_new = {\n",
    "    \"5us\": flat_5us,\n",
    "    \"50us\": flat_50us,\n",
    "    \"500us\": flat_500us,\n",
    "    \"5000us\": flat_5000us,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db63a5-a92c-4676-9d67-2fbe9ba93ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('readnoise/500us/fits/readnoise5_500us.fits') as hdul:\n",
    "    data = hdul[0].data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5081eb-26c4-48a6-9c39-d90249ef63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store mean signal levels and noise (standard deviation) for each exposure time\n",
    "mean_signals = []\n",
    "noise_values = []\n",
    "exposure_times = []\n",
    "rms_errors = []\n",
    "read_noise = None  # To store the estimated read noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f9525-babd-4196-8d1a-74eba3bd9783",
   "metadata": {},
   "source": [
    "### Load Flat Frames for Each Exposure Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fceb0-9b85-466a-aff0-2679d7f852f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flat_frames(files):\n",
    "    \"\"\"\n",
    "    Load a stack of flat frames from a list of FITS files.\n",
    "    This function reads the data from each FITS file and returns a numpy array of frames.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for file in files:\n",
    "        with fits.open(file) as hdul:\n",
    "            data = hdul[0].data  # Extract the image data\n",
    "            frames.append(data)   # Append the image data to the list\n",
    "    return np.array(frames)  # Convert the list of frames to a numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e37dc-3b6b-42e6-8f73-4f39418389ea",
   "metadata": {},
   "source": [
    "### Process the Flat Frames (ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0917a31-e41d-4253-a9f5-3c10ed6e7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exposure_time, flat_files in flat_files_dict.items():\n",
    "    print(f\"Processing exposure time: {exposure_time}\")\n",
    "\n",
    "    # Load the stack of flat frames for the current exposure time\n",
    "    flat_frames_stack = load_flat_frames(flat_files)\n",
    "\n",
    "    # Skip if no data is available for the current exposure time\n",
    "    if flat_frames_stack.size == 0:\n",
    "        print(f\"No data found for exposure time {exposure_time}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # ## Mean Frame and Residual Noise Calculation\n",
    "\n",
    "    # Calculate the mean frame across the stack (average pixel value for each pixel)\n",
    "    mean_frame = np.mean(flat_frames_stack, axis=0)\n",
    "\n",
    "    # Subtract the mean frame from each individual frame to obtain the residuals\n",
    "    residuals = flat_frames_stack - mean_frame\n",
    "\n",
    "    # Calculate the standard deviation (RMS noise) for each pixel across the stack\n",
    "    std_frame = np.std(residuals, axis=0)\n",
    "\n",
    "    # Calculate the overall mean signal and noise for this exposure time\n",
    "    mean_signal = np.mean(mean_frame)\n",
    "    noise = np.mean(std_frame)\n",
    "    \n",
    "    # Append the calculated mean signal and noise values to their respective lists\n",
    "    mean_signals.append(mean_signal)\n",
    "    noise_values.append(noise)\n",
    "    exposure_times.append(int(exposure_time.replace(\"us\", \"\")))  # Convert exposure time to integer for plotting\n",
    "\n",
    "    # ## Estimate Read Noise from the Shortest Exposure Time\n",
    "\n",
    "    if exposure_time == \"5us\":\n",
    "        read_noise = noise  # The noise from the shortest exposure is assumed to be dominated by read noise\n",
    "        print(f\"Read noise estimated from {exposure_time}: {read_noise} ADU\")\n",
    "\n",
    "    # ## Histogram of Noise for Current Exposure Time\n",
    "\n",
    "    # Plot a histogram of the noise (standard deviation) for the current exposure time\n",
    "    plt.figure()\n",
    "    plt.hist(std_frame.flatten(), bins=100, color='blue', alpha=0.7)\n",
    "    plt.title(f'Histogram of Noise: {exposure_time}')\n",
    "    plt.xlabel('Noise (ADU)')\n",
    "    plt.ylabel('Number of Pixels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d103ca-e681-4fb1-8593-166dce6f2493",
   "metadata": {},
   "source": [
    "### Plot Noise vs Exposure Time (ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c8971-5f50-487a-a32a-cda2c890ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Noise vs Exposure Time\n",
    "plt.figure()\n",
    "plt.plot(exposure_times, noise_values, 'o-', color='red', label='Noise vs Exposure Time')\n",
    "plt.title('Noise (RMS) vs Exposure Time')\n",
    "plt.xlabel('Exposure Time (µs)')\n",
    "plt.ylabel('Noise (RMS)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8b64f-e548-47d6-bf2a-6378d9b54eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store mean signal levels and noise (standard deviation) for each exposure time\n",
    "mean_signals_short = []\n",
    "noise_values_short = []\n",
    "exposure_times_short = []\n",
    "rms_errors_short = []\n",
    "read_noise_short = None  # To store the estimated read noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216bf7a-dbe8-4497-9c68-798dc9a5e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exposure_time, flat_files in flat_files_dict_new.items():\n",
    "    print(f\"Processing exposure time: {exposure_time}\")\n",
    "\n",
    "    # Load the stack of flat frames for the current exposure time\n",
    "    flat_frames_stack = load_flat_frames(flat_files)\n",
    "\n",
    "    # Skip if no data is available for the current exposure time\n",
    "    if flat_frames_stack.size == 0:\n",
    "        print(f\"No data found for exposure time {exposure_time}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # ## Mean Frame and Residual Noise Calculation\n",
    "\n",
    "    # Calculate the mean frame across the stack (average pixel value for each pixel)\n",
    "    mean_frame = np.mean(flat_frames_stack, axis=0)\n",
    "\n",
    "    # Subtract the mean frame from each individual frame to obtain the residuals\n",
    "    residuals = flat_frames_stack - mean_frame\n",
    "\n",
    "    # Calculate the standard deviation (RMS noise) for each pixel across the stack\n",
    "    std_frame = np.std(residuals, axis=0)\n",
    "\n",
    "    # Calculate the overall mean signal and noise for this exposure time\n",
    "    mean_signal = np.mean(mean_frame)\n",
    "    noise = np.mean(std_frame)\n",
    "    \n",
    "    # Append the calculated mean signal and noise values to their respective lists\n",
    "    mean_signals_short.append(mean_signal)\n",
    "    noise_values_short.append(noise)\n",
    "    exposure_times_short.append(int(exposure_time.replace(\"us\", \"\")))  # Convert exposure time to integer for plotting\n",
    "\n",
    "    # ## Estimate Read Noise from the Shortest Exposure Time\n",
    "\n",
    "    if exposure_time == \"5us\":\n",
    "        read_noise_short = noise  # The noise from the shortest exposure is assumed to be dominated by read noise\n",
    "        print(f\"Read noise estimated from {exposure_time}: {read_noise} ADU\")\n",
    "\n",
    "    # ## Histogram of Noise for Current Exposure Time\n",
    "\n",
    "    # Plot a histogram of the noise (standard deviation) for the current exposure time\n",
    "    plt.figure()\n",
    "    plt.hist(std_frame.flatten(), bins=100, color='blue', alpha=0.7)\n",
    "    plt.title(f'Histogram of Noise: {exposure_time}')\n",
    "    plt.xlabel('Noise (ADU)')\n",
    "    plt.ylabel('Number of Pixels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b46b3-9fa8-4bbe-a540-6e64b9b3571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Noise vs Exposure Time\n",
    "plt.figure()\n",
    "plt.plot(exposure_times_short, noise_values_short, 'o-', color='red', label='Noise vs Exposure Time')\n",
    "plt.title('(SHORT) Noise (RMS) vs Exposure Time')\n",
    "plt.xlabel('Exposure Time (µs)')\n",
    "plt.ylabel('Noise (RMS)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d18cb81-4bd0-4b42-90f9-e105c4eee2eb",
   "metadata": {},
   "source": [
    "### Analyzing Read Noise for Short Exposure Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c750f5-3bca-4cdc-8dc5-82473867b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exposure_time, flat_files in flat_files_dict_new.items():\n",
    "    print(f\"Processing exposure time: {exposure_time}\")\n",
    "\n",
    "    # Load the stack of flat frames for the current exposure time\n",
    "    flat_frames_stack = load_flat_frames(flat_files)\n",
    "\n",
    "    # Skip if no data is available for the current exposure time\n",
    "    if flat_frames_stack.size == 0:\n",
    "        print(f\"No data found for exposure time {exposure_time}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # ## Mean Frame and Residual Noise Calculation\n",
    "\n",
    "    # Calculate the mean frame across the stack (average pixel value for each pixel)\n",
    "    mean_frame = np.mean(flat_frames_stack, axis=0)\n",
    "\n",
    "    # Subtract the mean frame from each individual frame to obtain the residuals\n",
    "    residuals = flat_frames_stack - mean_frame\n",
    "\n",
    "    # Calculate the standard deviation (RMS noise) for each pixel across the stack\n",
    "    std_frame = np.std(residuals, axis=0)\n",
    "\n",
    "    # Calculate the overall RMS error for this exposure time\n",
    "    rms_error = np.sqrt(np.mean(std_frame**2))  # Root-mean-square error for the current exposure\n",
    "    rms_errors.append(rms_error)  # Append the RMS error to the list\n",
    "\n",
    "    # Print the RMS error for the current exposure time\n",
    "    print(f\"RMS error for {exposure_time}: {rms_error} ADU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb803d0-2d3d-4dbe-8d29-783bb7e549fe",
   "metadata": {},
   "source": [
    "### Print Read Noise Estimate from Dark Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fe47a-0560-45f6-af6d-583cde8746f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and Print the Combined RMS Error for All Exposure Times\n",
    "\n",
    "read_noise_error = np.sqrt(np.mean(np.array(rms_errors)**2))\n",
    "print(f\"Combined RMS error across 5us, 50us, 500us, and 5000us: {np.round(read_noise_error,4)} ADU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c9f2c-5658-4638-925b-fe09c8558abd",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ddf0ec-3abf-46fb-904e-f5518ea32512",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exposure time in microseconds (us)\n",
    "exposure_time = 1000  # Placeholder value for noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048503b-891e-4bd8-8f9f-f61454509166",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Directories for RAW and FITS data of different exposures\n",
    "raw_red_spot_05s_directory = \"red_spot/05s/raw\"\n",
    "fits_red_spot_05s_directory = \"red_spot/05s/fits\"\n",
    "\n",
    "raw_red_spot_1s_directory = \"red_spot/1s/raw\"\n",
    "fits_red_spot_1s_directory = \"red_spot/1s/fits\"\n",
    "\n",
    "raw_red_spot_2s_directory = \"red_spot/2s/raw\"\n",
    "fits_red_spot_2s_directory = \"red_spot/2s/fits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b914a2-c5a6-44de-8392-6027c05a1731",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert RAW data to FITS format for further analysis\n",
    "process_raw_to_fits(raw_directory=raw_red_spot_05s_directory,\n",
    "                    fits_directory=fits_red_spot_05s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_red_spot_1s_directory,\n",
    "                    fits_directory=fits_red_spot_1s_directory,\n",
    "                    shape=(1080, 1440))\n",
    "\n",
    "process_raw_to_fits(raw_directory=raw_red_spot_2s_directory,\n",
    "                    fits_directory=fits_red_spot_2s_directory,\n",
    "                    shape=(1080, 1440))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1ecea-41f9-4257-b31b-228152c9ae4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FITS files for different exposure times\n",
    "red_spot_500000us_file = \"red_spot/05s/fits/red_spot1_500000us.fits\"\n",
    "red_spot_1000000us_file = \"red_spot/1s/fits/red_spot1_1000000us.fits\"\n",
    "red_spot_2000000us_file = \"red_spot/2s/fits/red_spot1_2000000us.fits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e96d47-2d05-46bc-9b0e-3ec40fca63ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Assuming a standard frame shape of 1080 x 1440 pixels\n",
    "frame_shape = (1080, 1440)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ac57a-dfcb-48d7-8dc3-863cff5c3d77",
   "metadata": {},
   "source": [
    "### Creating the Bias Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef66a8-9ed0-43d8-a5e9-14b0e699c58f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a bias frame (a constant value across the frame)\n",
    "def create_bias_frame(bias_level, frame_shape):\n",
    "    \"\"\"\n",
    "    Creates a bias frame with a constant bias level across all pixels.\n",
    "    \"\"\"\n",
    "    \n",
    "    bias_frame = np.full(frame_shape, bias_level)\n",
    "    print(f\"Bias Frame Created: Bias level set to {bias_level} ADU per pixel.\")\n",
    "    return bias_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4136f66-7194-41bf-acc2-3c7831e192fe",
   "metadata": {},
   "source": [
    "### Creating the Dark Current Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc504b57-ead5-4957-aa1f-10f481ca6a90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate a dark frame based on the dark current slope and exposure time\n",
    "def create_dark_frame(slope, exposure_time, frame_shape):\n",
    "    \"\"\"\n",
    "    Creates a dark frame based on dark current slope and exposure time.\n",
    "    Dark current accumulates linearly with exposure.\n",
    "    \"\"\"\n",
    "    \n",
    "    dark_frame = slope * exposure_time\n",
    "    print(f\"Dark Frame Created: slope = {slope} ADU/us, exposure = {exposure_time} us.\")\n",
    "    return np.full(frame_shape, dark_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5363344-b1b4-44a6-8089-f77d0dd1b29e",
   "metadata": {},
   "source": [
    "### Creating the Flat Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e89ff-d1c4-4710-93f1-cb96d71036f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a flat frame with random variations, and subtract bias/dark frames\n",
    "def create_flat_frame(bias_frame, dark_frame, combined_rms_error, frame_shape):\n",
    "    \"\"\"\n",
    "    Creates a flat frame with small pixel-to-pixel variations, \n",
    "    subtracts bias and dark frames, and normalizes the result.\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_frame = np.ones(frame_shape) + np.random.normal(0, combined_rms_error, frame_shape)\n",
    "    print(f\"Flat Frame Created: RMS error set to {combined_rms_error}.\")\n",
    "    \n",
    "    # Normalize the flat frame after subtracting bias and dark contributions\n",
    "    normalized_flat_frame = (flat_frame - bias_frame - dark_frame) / np.median(flat_frame - bias_frame - dark_frame)\n",
    "    print(\"Flat Frame Normalized.\")\n",
    "    return normalized_flat_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15027dbb-e82b-4ead-8a40-cb476362c2cc",
   "metadata": {},
   "source": [
    "### Clean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffd174-7b8c-45d7-b8fc-4806b28fe594",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Clean an object frame by subtracting bias, dark, and correcting with flat frame\n",
    "def clean_frame(object_frame, bias_frame, dark_frame, normalized_flat_frame):\n",
    "    \"\"\"\n",
    "    Cleans an object frame by subtracting bias and dark frames, \n",
    "    and dividing by the normalized flat frame to correct pixel variations.\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_frame = (object_frame - bias_frame - dark_frame) / normalized_flat_frame\n",
    "    print(\"Frame successfully cleaned.\")\n",
    "    return cleaned_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a78a7c-7b7f-44b5-9792-9db129fb8e54",
   "metadata": {},
   "source": [
    "### Load the Red Spot Images and Clean Them (for specific files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5aa9b-bba7-4c93-96a1-c441e18a3add",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and clean red spot image, display raw and cleaned image\n",
    "def load_and_clean_red_spot_image(file_path, bias_frame, dark_frame, flat_frame, is_fits=True):\n",
    "    \"\"\"\n",
    "    Loads an image file (FITS or RAW), displays the raw image, \n",
    "    cleans the image by subtracting bias, dark, and correcting with flat, \n",
    "    then displays the cleaned image.\n",
    "    \"\"\"\n",
    "    if is_fits:\n",
    "        with fits.open(file_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "            print(f\"Loaded FITS file: {file_path}\")\n",
    "    else:\n",
    "        data = np.fromfile(file_path, dtype='uint16').reshape(1080, 1440)\n",
    "        print(f\"Loaded RAW file: {file_path}\")\n",
    "\n",
    "    # Display raw image\n",
    "    plt.imshow(data, cmap='gray')\n",
    "    plt.title(f\"Raw Image: {file_path}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Clean the raw data\n",
    "    cleaned_data = clean_frame(data, bias_frame, dark_frame, flat_frame)\n",
    "\n",
    "    # Display cleaned image\n",
    "    plt.imshow(cleaned_data, cmap='gray')\n",
    "    plt.title(f\"Cleaned Image: {file_path}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eff3c4-bd57-4dd8-8621-8e91dbc66ac6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate frames based on given bias level, slope, and RMS error\n",
    "bias_frame = create_bias_frame(bias_level, frame_shape)\n",
    "dark_frame = create_dark_frame(slope, exposure_time, frame_shape)\n",
    "flat_frame = create_flat_frame(bias_frame, dark_frame, combined_rms_error, frame_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d74d6f-3eb0-43dc-86d8-dcad1f4812e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process specific red spot images\n",
    "print(\"Processing red_spot1_500000us.fits...\")\n",
    "load_and_clean_red_spot_image(red_spot_500000us_file, bias_frame, dark_frame, flat_frame)\n",
    "\n",
    "print(\"Processing red_spot1_1000000us.fits...\")\n",
    "load_and_clean_red_spot_image(red_spot_1000000us_file, bias_frame, dark_frame, flat_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610aa4f-d5de-4a59-9df9-47aaa88a80fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
